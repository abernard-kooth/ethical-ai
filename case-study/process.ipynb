{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Responsible Innovation and Ethical AI Process\n",
    "The following points are from the [The Alan Turing Institute's ethical AI and responsible innovation guide](https://www.turing.ac.uk/sites/default/files/2019-06/understanding_artificial_intelligence_ethics_and_safety.pdf).   \n",
    "\n",
    "AI ethics is a set of values, principles, and techniques that employ widely accepted standards of right and wrong to guide moral conduct in the development and use of AI technologies.   \n",
    "\n",
    "The field of AI ethics has largely emerged as a response to the range of individual and societal harms that the misuse, abuse, poor design, or negative unintended consequences of AI systems may cause. The potential harms of AI include:  \n",
    "- Reproducing and amplifying patterns of marginalization and discrimination that exist in society  \n",
    "- Complicating the designation of responsibility in algorithmically generated outcomes, potentially harming the autonomy and violating the rights of affected individuals  \n",
    "- Producing non-transparent, unexplainable, or unjustifiable results in some cases  \n",
    "- Posing threats to privacy in both design and development processes and deployment  \n",
    "- Reducing the need for human-to-human interaction, leading to isolation and disintegration of social connections  \n",
    "- Being used to manipulate or deceive people  \n",
    "- Creating negative unintended consequences, such as environmental harm or job displacement  \n",
    "- Being used to perpetrate or enable harm, such as through cyber attacks or misuse of autonomous weapons  \n",
    "\n",
    "When implementing an ethical AI governance architecture, we must ensure that AI projects are:  \n",
    "- Ethically permissible by considering the impacts they may have on the wellbeing of affected stakeholders and communities\n",
    "- Fair and non-discriminatory by accounting for their potential to have discriminatory effects on individuals and social groups, by mitigating biases that may influence their outputs, and by being aware of the issues surrounding fairness that come into play at every phase of the design and implementation process\n",
    "- Worthy of public trust by guaranteeing to the extent possible the safety, accuracy, reliability, security, and robustness of their products\n",
    "- Justifiable by prioritizing both the transparency of the process by which they are designed and implemented, and the transparency and interpretability of their decisions and behaviours  \n",
    "\n",
    "We call this governance architecture an **ethical platform**. It will take three building blocks to make such an ethical platform possible:  \n",
    "1. **Reflect using the SUM Values** (Respect, Connect, Care, Protect) to provide a framework for ethical values and evaluate the ethical permissibility of the project\n",
    "2. **Act using the FAST Track Principles** (Fairness, Accountability, Sustainability, Transparency) to ensure the project is bias-mitigating, non-discriminatory, responsible, trustworthy and fair\n",
    "3. **Justify using the PBG Framework** (Pocess-Based Governance) to operationalize the SUM Values and FAST Track Principles, ensuring end-to-end transparency and accountability\n",
    "\n",
    "All definitions will be described within the context of the following AI project lifecycle:  \n",
    "**Problem Formulation > Data Extraction and Aquisition > Data Preprocessing > Modelling, Testing and Validation > Deploy, Monitor and Reassess**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflect: SUM Values\n",
    "These values should orient you in deliberating about the ethical permissibility of a prospective AI project. They should also provide you with a framework of concepts to consider\n",
    "the ethical impacts of an AI system across the design, use, and monitoring lifecycle.\n",
    "- **Respect** the dignity of individual persons by safeguarding their autonomy, their power to express themselves, and their right to be heard, and supporting their abilities to flourish and fully develop themselves  \n",
    "- **Connect** with each other sincerely, openly, and inclusively, prioritising diversity, participation, and inclusion in the design, development, and deployment processes of AI innovation\n",
    "- **Care** for the wellbeing of all stakeholders by designing and deploying AI systems to foster and cultivate their welfare, minimising the risks of misuse or abuse, and prioritising safety\n",
    "- **Protect** the priorities of social values, justice, and social equity by prioritising social welfare, public interest, utilitarianism and the consideration wider impact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Act: FAST Track Principles\n",
    "#### Fairness\n",
    "Consider the principle of **discriminatory non-harm** as a minimum required threshold of fairness, ensuring that AI systems:\n",
    "1. Are trained and tested on properly representative, relevant, accurate, and\n",
    "generalisable datasets (Data Fairness)\n",
    "2. Have model architectures that do not include target variables, features,\n",
    "processes, or analytical structures\n",
    "which are unreasonable, morally objectionable, or unjustifiable (Design\n",
    "Fairness)\n",
    "3. Do not have discriminatory or inequitable impacts on the lives of the people\n",
    "they affect (Outcome Fairness)\n",
    "4. Are deployed by users sufficiently trained to implement them responsibly and\n",
    "without bias (Implementation Fairness)  \n",
    "\n",
    "Self Assessment:\n",
    "1. Identify the fairness and bias mitigation dimensions that apply to the specific\n",
    "stage under consideration\n",
    "2. Scrutinise how your particular AI project might pose risks or have unintended\n",
    "vulnerabilities in each of these areas\n",
    "3. Correct any existing problems that have been identified,\n",
    "strengthen areas of weakness that have possible discriminatory consequences, and take\n",
    "proactive bias-prevention measures  \n",
    "\n",
    "#### Accountability\n",
    "Data processing that is aligned with [Principle 6 of the GOV.UK Data Ethics Framework](https://www.gov.uk/government/publications/data-ethics-framework/data-ethics-framework-2020) and following an **accountability-by-design** approach:   \n",
    "AI systems must be designed to facilitate end-to-end: **answerability** (who is accountable, with clear justification) and **auditability** (how the designers and implementers of AI systems are to be held accountable).   \n",
    "This requires both **responsible humans-in-the-loop** across the entire design and implementation chain as well as **activity monitoring protocols** that enable end-to-end oversight and review.     \n",
    "Involving both:\n",
    "- **Anticipatory Accountability**: defined prior to implementation, bolstering soundness of design/implementation processes and thereby more effectively pre-empting possible harms\n",
    "- **Remedial Accountability**: including comprehensive auditability regimes, transparent design/use practices, decision rationale, explicability of model results, and explanation of the ethical permissibility  \n",
    "\n",
    "#### Sustainability\n",
    "Conduct a **Stakeholder Impact Assessment** (SIA) which should be considered at Problem Formulation (initial assessment), Pre-Implementation (review and public consultation) and Reassessment (reflect and rectify). It should cover the following questions:\n",
    "1. Identifying Affected Stakeholders\n",
    "    - Who are the stakeholders that this AI project is most likely to affect? \n",
    "    - What groups of these stakeholders are most vulnerable? How might the project negatively impact them?\n",
    "2. Goal-Setting and Objective-Mapping\n",
    "    - How are you defining the outcome (the target variable) that the system is optimising for? Is this a fair, reasonable, and widely acceptable definition? \n",
    "    - Does the target variable (or its measurable proxy) reflect a reasonable and justifiable translation of the project’s objective into the statistical frame? \n",
    "    - Is this translation justifiable given the general purpose of the project and the potential impacts that the outcomes of its implementation will have on the communities involved? \n",
    "3. Possible Impacts on the Individual\n",
    "    - How might the implementation of your AI system impact the abilities of affected stakeholders to make free, independent, and well-informed decisions about their lives? How might it enhance or diminish their autonomy?\n",
    "    - How might it affect their capacities to flourish and to fully develop themselves?\n",
    "    - How might it do harm to their physical or mental integrity? Have risks to individual health and safety been adequately considered and addressed?\n",
    "    - How might it infringe on their privacy rights, both on the data processing end of designing the system and on the implementation end of deploying it \n",
    "4. Possible Impacts on Society and Interpersonal Relationships \n",
    "    - How might the implementation of your AI system adversely affect each stakeholder’s fair and equal treatment under the law? Are there any aspects of the project that expose vulnerable communities to possible discriminatory harm?\n",
    "    - Have the values of civic participation, inclusion, and diversity been adequately considered in articulating the purpose and setting the goals of the project? If not, how might these values be incorporated into your project design?\n",
    "    - Does the project aim to advance the interests and well-being of as many affected individuals as possible? Might any disparate socioeconomic impacts result from its deployment?\n",
    "    - Have you sufficiently considered the wider impacts of the system on future generations and on the planet as a whole?  \n",
    "\n",
    "A technically sustainable AI system is safe, accurate, reliable, secure, and robust. In order to safeguard that your AI system functions safely, you must prioritise the technical objectives of accuracy, reliability, security, and robustness. This requires that your technical team put careful forethought into how to construct a system that accurately and dependably operates in accordance with its designers’ expectations even when confronted with unexpected changes, anomalies, and perturbations. Building an AI system that meets these safety goals also requires rigorous testing, validation, and re-assessment as well as the integration of adequate mechanisms of oversight and control into its real-world operation.\n",
    "- **Accuracy and Performance Metrics**: confidence depends on problems inherent in modeling a chaotic and changing reality, including noise in data, missing features, and changes in input data over time\n",
    "- **Reliability**: measure of consistency, ensuring that system behaves as intended and adheres to specifications\n",
    "- **Security**: protection of system from unauthorized modification or damage, ensuring that it remains functional and accessible to authorized users and keeps confidential information secure\n",
    "- **Robustness**: ability of system to function reliably and accurately under harsh conditions, including adversarial attacks, perturbations, and undesirable reinforcement learning behavior  \n",
    "\n",
    "Risks relating to accuracy and reliability:  \n",
    "- **Concept Drift**: model accuracy and reliability can be compromised by changes in the underlying data distribution that the model was trained on\n",
    "- **Brittleness**: machine learning systems may have difficulty processing unfamiliar events and scenarios and may make unexpected mistakes, especially in safety-critical applications\n",
    "\n",
    "Risks relating to security and robustness: \n",
    "- **Adversarial Attacks**: maliciously modifying input data to induce incorrect predictions or misclassification, which can have serious consequences for safety-critical applications ([toolbox]( https://github.com/IBM/adversarialrobustness-toolbox))\n",
    "- **Data Poisoning**: compromising data sources at collection and pre-processing stage to induce trained AI system into curated misclassification, systemic malfunction, and poor performance\n",
    "- **Data Procurement**: obtaining data from potentially unreliable or questionable sources, such as the internet, social media, or the Internet of Things, or through third-party data curation processes  \n",
    "- **Misdirected Reinforcement Learning Behavior**: risk that a reinforcement learning system will determine a reward-optimizing course of action that is harmful to people, because the system lacks context-awareness and common sense\n",
    "\n",
    "Safety risks in an AI project depend on various factors such as the algorithm and machine learning techniques being used, the type of application in which they are being deployed, the provenance of the data, the objective specification, and the problem domain. It is best practice to consider safety at every stage of the AI project lifecycle, including testing, validating, verifying, and monitoring the safety of the system and performing AI safety self-assessments. These self-assessments should evaluate the team's design and implementation practices in relation to the safety objectives of accuracy, reliability, security, and robustness. They should be logged and subject to review and re-assessment.\n",
    "\n",
    "#### Transparency\n",
    "TBC\n",
    "\n",
    "The principles of accountability and transparency are end-to-end governing principles. Fairness and sustainability are qualities of algorithmic systems for which their designers and implementers are held accountable through the transparency both of the outcomes of their practices and of the practices themselves. These four principles are therefore all deeply interrelated, but they are not\n",
    "equal. Fairness, accountability and transparency are also a legal requirement under [GDPR (General Data Protection Regulation)](https://ico.org.uk/for-organisations/guide-to-data-protection/guide-to-the-general-data-protection-regulation-gdpr/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
